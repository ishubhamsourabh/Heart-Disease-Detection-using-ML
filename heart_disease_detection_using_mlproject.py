# -*- coding: utf-8 -*-
"""Heart Disease Detection using MLProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EBGKEPoNX6uKiMikMXHnbeNR6oLPGitl
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
# %matplotlib inline
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay
from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve, roc_auc_score,auc
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import f1_score
import warnings
import pickle

from google.colab import drive
drive.mount('/content/drive')

import warnings

warnings.filterwarnings("ignore")

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier

df = pd.read_csv("/content/drive/MyDrive/Project Heart Disease/Iraq hospital dataset.csv")

df.head()

df.tail()

df.shape

df.isnull().sum()

df.keys()

df.rename(columns={'class': 'target'}, inplace=True)

df['target'] = df['target'].replace({'positive': 1, 'negative': 0})

df['target'].value_counts()

#Graphical Representation of count value of class column
color = ['r','g']
df['target'].value_counts().plot(kind='bar',color =color)
plt.xlabel("1 or 0")
plt.ylabel("Count")
plt.title("Target Count Graph")
plt.show()

df.info()

df.describe()

import warnings
warnings.simplefilter("ignore", category=RuntimeWarning)
cormat = df.corr()
print(cormat)
cormat = cormat.dropna(how = 'all', axis=1)
cormat = cormat.dropna(how = 'all', axis=0)
cormat.style.background_gradient(cmap='coolwarm')

cormat.describe()

"""## function for final dataset"""

def getCorrelationFeature(corrdata,threshold):
    feature=[]
    value=[]
    for i,index in enumerate(corrdata.index):
        if abs(corrdata[index])>threshold:
            feature.append(index)
            value.append(corrdata[index])
    df=pd.DataFrame(data=value,index=feature,columns=['corr values'])
    return df

threshold=0.03
corr_value=getCorrelationFeature(cormat['target'],threshold)
corr_value

correlated_data=df[corr_value.index]
correlated_data.head()

correlated_data.shape

correlated_data.var()

import statsmodels.api as sm

def calculate_vif(data_frame):
    vif_data = pd.DataFrame()
    vif_data["Variable"] = data_frame.columns
    vif_data["VIF"] = [sm.OLS(data_frame[col], sm.add_constant(data_frame.drop(columns=[col]))
                         ).fit().rsquared for col in data_frame]
    return vif_data

# Apply VIF to your training data
vif_data = calculate_vif(correlated_data)
print(vif_data)

cr = correlated_data.corr()
cr.style.background_gradient(cmap='coolwarm')

fig , ax = plt.subplots(figsize=(20,20))
sns.heatmap(cr, cmap='coolwarm', center=0, annot=True)
plt.savefig("hea_t.png",dpi=300)
#sns.heatmap(cr, cmap='BrBG', center=0, annot=True)
#sns.heatmap(cr, annot=True, ax=ax)

"""## TRAIN TEST SPLIT"""

#Splitting the data into train and test case
x=correlated_data.drop(labels=['target'],axis=1)
y=correlated_data['target']
x.head()

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)

print(X_train.shape,X_test.shape)

y_train.shape,y_test.shape

test_y = np.array(y_test)
test_y

y_train =np.array(y_train)
y_train

X_test

"""# Feature Scaling"""

scaler = StandardScaler()
x_train=scaler.fit_transform(X_train)
x_test=scaler.fit_transform(X_test)

x_test

"""## WORK FOR TRAINING DATA

Cross validation
"""

#list of models
models = [LogisticRegression(max_iter=30000),SVC(kernel='linear',probability=True),KNeighborsClassifier(n_neighbors=10),RandomForestClassifier(random_state=42, n_jobs=-1, max_depth=5,
                                       n_estimators=50),GaussianNB(),DecisionTreeClassifier(max_depth = 5) ]

def compare_models_cross_validation():
    mean_accuracy = []
    mean_precision = []
    mean_recall = []
    mean_f1 = []
    for model in models:
        cv_score = cross_val_score(model,x_train,y_train,cv=15)
        mean_acc = (sum(cv_score)/len(cv_score))
        mean_accuracy.append(mean_acc)
        mean_prec = cross_val_score(model,x_train,y_train,scoring = 'precision',cv=15).mean()
        mean_precision.append(mean_prec)
        mean_rec = cross_val_score(model,x_train,y_train,scoring = 'recall',cv=15).mean()
        mean_recall.append(mean_rec)
        mean_f1_score = cross_val_score(model,x_train,y_train,scoring = 'f1',cv=15).mean()
        mean_f1.append(mean_f1_score)
        #y_cv_pred= cross_val_predict(model,x_train,y_train,cv=10)
        #y_cv_tpred= cross_val_predict(model,x_test,y_test,cv=10)
    return mean_accuracy,mean_precision,mean_recall,mean_f1

mean_accuracy,mean_precision,mean_recall,mean_f1= compare_models_cross_validation()
for i,model in enumerate(models):
    print("---------------------------------------")
    print("Model:",model)
    print('Mean Accuracy = ',mean_accuracy[i])
    print('Mean Precision = ',mean_precision[i])
    print('Mean Recall = ',mean_recall[i])
    print('Mean F1_score = ',mean_f1[i])
    #print('y_train prediction',y_cv_pred[i])
    #print('y_testing prediction',y_cv_tpred[i])
    print("-------------------------------------")

def ytprediction():
    y_pred_train = []
    for model in models:
        model.fit(x_train,y_train)
        ytrain_pred = model.predict(x_train)
        y_pred_train.append(ytrain_pred)
    return y_pred_train

y_pred_train=ytprediction()

y_pred_train[0]

"""
## CONFUSION MATRIX"""

def train_conf_matrix():
    for i, model in enumerate(models):
        cf_matrix = confusion_matrix(y_train,y_pred_train[i])
        ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')

        ax.set_title('Training Confusion Matrix with labels\n\n');
        ax.set_xlabel('\nPredicted ')
        ax.set_ylabel('Actual  ');
        plt.show()
        print(model)
        print('*******************************************************')
        print()

train_conf_matrix()

def dp():
    tacc = []
    tprec = []
    trec = []
    tf1 = []
    #y_pred_train = []
    for i, model in enumerate(models):
        #ytrain_pred = model.predict(x_train)
        #y_pred_train.append(ytrain_pred)
        accuracy = metrics.accuracy_score(y_train,y_pred_train[i])
        #print(accuracy)
        tacc.append(accuracy)
        precision=metrics.precision_score(y_train,y_pred_train[i])
        #print(precision)
        tprec.append(precision)
        recall = metrics.recall_score(y_train,y_pred_train[i])
        #print(recall)
        trec.append(recall)
        t_f1=metrics.f1_score(y_train,y_pred_train[i])
        #print(t_f1)
        tf1.append(t_f1)
    return tacc,tprec,trec,tf1

tacc,tprec,trec,tf1 = dp()

def aprf():
    print('Displaying the values for the train data')
    for i, model in enumerate(models):
        print('-------------------------------------------------------')
        print('Accuracy of the ',model,'=',tacc[i])
        print('Precision of the ',model,'=',tprec[i])
        print('Recall of the ',model,'=',trec[i])
        print('F1 score of the ',model,'=',tf1[i])
        print('---------------------------------------------------------')

aprf()

"""# GRAPH FOR THE TRAIN DATA

# TRAINING ACCURACY GRAPH
"""

#graph plotting
val = {'LR':tacc[0],'SVM':tacc[1],'KNN':tacc[2],'RF':tacc[3],'NB':tacc[4],'DT':tacc[5]}
model_name = list(val.keys())
values = list(val.values())


axes = plt.axes()
axes.set_ylim([0.60, 1.0])
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('Accuracy Graph')
color = ['r','g','b','c','m','y','g','r']
plt.bar(model_name,values,color=color,width = 0.4)
plt.show()

mod = pd.DataFrame({
    'Model': ['LR','SVM','KNN', 'RF', 'NB','DT'],
    'Score': [
        tacc[0],
        tacc[1],
        tacc[2],
        tacc[3],
        tacc[4],
        tacc[5]

    ]})
mod.sort_values(by='Score', ascending=False)

"""# TRAINING PRECISION GRAPH"""

val = {'LR':tprec[0],'SVM':tprec[1],'KNN':tprec[2],'RF':tprec[3],'NB':tprec[4],'DT':tprec[5]}
model_name = list(val.keys())
values = list(val.values())


axes = plt.axes()
axes.set_ylim([0.60, 1.0])
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('Precision Graph')
color = ['r','g','b','c','m','y','g','r']
plt.bar(model_name,values,color=color,width = 0.4)
plt.show()

mod = pd.DataFrame({
     'Model': ['Logistic Regression','SVM','KNN', 'Random Forest', 'Naive Bayes','Decision Tree'],
    'Score': [
        tprec[0],
        tprec[1],
        tprec[2],
        tprec[3],
        tprec[4],
        tprec[5]

    ]})
mod.sort_values(by='Score', ascending=False)

"""# TRAINING RECALL GRAPH"""

val = {'LR':trec[0],'SVM':trec[1],'KNN':trec[2],'RF':trec[3],'NB':trec[4],'DT':trec[5]}
model_name = list(val.keys())
values = list(val.values())


axes = plt.axes()
axes.set_ylim([0.60, 1.0])
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('Recall Graph')
color = ['r','g','b','c','m','y','g','r']
plt.bar(model_name,values,color=color,width = 0.4)
plt.show()

mod = pd.DataFrame({
     'Model': ['Logistic Regression','SVM','KNN', 'Random Forest', 'Naive Bayes','Decision Tree'],
    'Score': [
        trec[0],
        trec[1],
        trec[2],
        trec[3],
        trec[4],
        trec[5]

    ]})
mod.sort_values(by='Score', ascending=False)

"""# TRAINING F1 SCORE GRPAH"""

val = {'LR':tf1[0],'SVM':tf1[1],'KNN':tf1[2],'RF':tf1[3],'NB':tf1[4],'DT':tf1[5]}
model_name = list(val.keys())
values = list(val.values())


axes = plt.axes()
axes.set_ylim([0.60, 1.0])
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('F1 SCORE  Graph')
color = ['r','g','b','c','m','y','g','r']
plt.bar(model_name,values,color=color,width = 0.4)
plt.show()

mod = pd.DataFrame({
    'Model': ['Logistic Regression','SVM','KNN', 'Random Forest', 'Naive Bayes','Decision Tree'],
    'Score': [
        tf1[0],
        tf1[1],
        tf1[2],
        tf1[3],
        tf1[4],
        tf1[5]

    ]})
mod.sort_values(by='Score', ascending=False)

"""**bold text**# TRAINING ROC CURVE"""

def trc_curv():
    for i,model in enumerate(models):
        cr_probs = model.predict_proba(x_train)
        cr_probs = cr_probs[:, 1]
        cr_auc = roc_auc_score(y_train, cr_probs)
        cr_fpr,cr_tpr, _ = roc_curve(y_train,cr_probs)
        print(model)
        print('----------------------------------------------------------------------------------')
        plt.plot(cr_fpr,cr_tpr, marker='*',label='(AUROC = %0.10f)'% cr_auc)
        plt.plot([0, 1], [0, 1],'r--')
        plt.title('ROC PLOT')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.legend()
        # plt.savefig('roc_grpah01.jpg', dpi = 1200)
        # plt.savefig('roc_grpah02.jpg', dpi = 1200)
        # plt.savefig('roc_grpah03.jpg', dpi = 1200)
        # plt.savefig('roc_grpah04.jpg', dpi = 1200)
        # plt.savefig('roc_grpah05.jpg', dpi = 1200)
        # plt.savefig('roc_grpah06.jpg', dpi = 1200)
        plt.show()
        print('--------------------------------------------------------------------------------')

trc_curv()

"""# TRAINING ROC CURVE"""

lr_probs = models[0].predict_proba(x_train)
sv_probs = models[1].predict_proba(x_train)
kn_probs = models[2].predict_proba(x_train)
rf_probs = models[3].predict_proba(x_train)
nb_probs = models[4].predict_proba(x_train)
dt_probs = models[5].predict_proba(x_train)

#Probabilities for the positive outcome is kept.
lr_probs = lr_probs[:, 1]
sv_probs = sv_probs[:, 1]
rf_probs = rf_probs[:, 1]
kn_probs = kn_probs[:, 1]
nb_probs = nb_probs[:, 1]
dt_probs = dt_probs[:, 1]

lr_auc = roc_auc_score(y_train, lr_probs)
rf_auc = roc_auc_score(y_train, rf_probs)
nb_auc = roc_auc_score(y_train, nb_probs)
sv_auc = roc_auc_score(y_train, sv_probs)
kn_auc = roc_auc_score(y_train, kn_probs)
dt_auc = roc_auc_score(y_train, dt_probs)

#printing AUROC  scores
print('Logistic : AUROC = %.10f' % (lr_auc))
print('SVM : AUROC = %.10f' % (sv_auc))
print('Random Forest: AUROC = %.10f' % (rf_auc))
print('KNN : AUROC = %.10f' % (kn_auc))
print('Naive Bayes: AUROC = %.10f' % (nb_auc))
print('Decision Tree: AUROC = %.10f' % (dt_auc))

#Calculate ROC curve
lr_fpr,lr_tpr, _ = roc_curve(y_train,lr_probs)
sv_fpr,sv_tpr, _ =  roc_curve(y_train, sv_probs)
rf_fpr, rf_tpr, _ = roc_curve(y_train, rf_probs)
kn_fpr,kn_tpr, _ = roc_curve(y_train, kn_probs)
nb_fpr, nb_tpr, _ = roc_curve(y_train, nb_probs)
dt_fpr, dt_tpr, _ = roc_curve(y_train, dt_probs)

#plotting the diagram
plt.plot(lr_fpr,lr_tpr, marker='*', label='Logistic (AUROC = %0.10f)' % lr_auc)
plt.plot(sv_fpr,sv_tpr, marker='.', label='SVM (AUROC = %0.10f)' % sv_auc)
plt.plot(rf_fpr, rf_tpr, marker='+', label='Random Forest (AUROC = %0.10f)' % rf_auc)
plt.plot(kn_fpr,kn_tpr, marker='x', label='KNN (AUROC = %0.10f)' % kn_auc)
plt.plot(nb_fpr, nb_tpr, marker='d', label='Naive Bayes (AUROC = %0.10f)' % nb_auc)
plt.plot(dt_fpr, dt_tpr, marker='p', label='Decision Tree (AUROC = %0.10f)' % dt_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.title('TRAINING ROC PLOT')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
#plt.savefig('roc_grpah.jpg')
plt.show()

"""# WORK FOR THE TEST DATA

# Comparing the performance of the model
"""

def tst_train():
    lst = []
    for model in models:
        y_pred = model.predict(x_test)
        lst.append(y_pred)
    return lst

y_pred = tst_train()
print(y_pred)

def model_fitting():
    for i,model in enumerate(models):
        cf_matrix = confusion_matrix(test_y,y_pred[i])
        ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')

        ax.set_title('Confusion Matrix with labels\n\n');
        ax.set_xlabel('\nPredicted ')
        ax.set_ylabel('Actual  ');
        plt.show()
        print(model)
        print('*******************************************************')
        print()

model_fitting()

def comp():
    acc=[]
    pre=[]
    rec=[]
    f1_s=[]
    for i,model in enumerate(models):
        accuracy = metrics.accuracy_score(test_y,y_pred[i])
        acc.append(accuracy)
        precision = metrics.precision_score(test_y,y_pred[i])
        pre.append(precision)
        recall = metrics.recall_score(test_y, y_pred[i])
        rec.append(recall)
        fscore = metrics.f1_score(test_y, y_pred[i])
        f1_s.append(fscore)
    return acc,pre,rec,f1_s

acc,pre,rec,f1_s = comp()

def display():
    target_names = ['1', '0']
    for i,model in enumerate(models):
        print('Accuracy score of the',model,'=',acc[i],'\n')
        print('Precision score of the',model,'=',pre[i],'\n')
        print('Recall score of the',model,'=',rec[i],'\n')
        print('f1 score of the ',model,'=',f1_s[i],'\n')
        print('**********************************************************************')
        print(classification_report(test_y, y_pred[i], target_names=target_names))
        print('-------------------------------------------------------------------------')

display()

"""# ACCURACY GRAPH"""

#graph plotting
val = {'LR':acc[0],'SVM':acc[1],'KNN':acc[2],'RF':acc[3],'NB':acc[4],'DT':acc[5]}
model_name = list(val.keys())
values = list(val.values())


axes = plt.axes()
axes.set_ylim([0.60, 1.0])
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('Accuracy Graph')
color = ['r','g','b','c','m','y','g','r']
plt.bar(model_name,values,color=color,width = 0.4)
plt.show()
#plt.savefig('Accuracy_bar.jpg')

mod = pd.DataFrame({
    'Model': ['Logistic Regression','SVM','KNN', 'Random Forest', 'Naive Bayes','Decision Tree'],
    'Score': [
        acc[0],
        acc[1],
        acc[2],
        acc[3],
        acc[4],
        acc[5]

    ]})
mod.sort_values(by='Score', ascending=False)

"""# PRECISION GRAPH"""

val = {'LR':pre[0],'SVM':pre[1],'KNN':pre[2],'RF':pre[3],'NB':pre[4],'DT':pre[5]}
model_name = list(val.keys())
values = list(val.values())


axes = plt.axes()
axes.set_ylim([0.60, 1.0])
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('Precision Graph')
color = ['r','g','b','c','m','y','g','r']
plt.bar(model_name,values,color=color,width = 0.4)
plt.show()

mod = pd.DataFrame({
    'Model': ['Logistic Regression','SVM','KNN', 'Random Forest', 'Naive Bayes','Decision Tree'],
    'Score': [
        pre[0],
        pre[1],
        pre[2],
        pre[3],
        pre[4],
        pre[5]

    ]})
mod.sort_values(by='Score', ascending=False)

"""# RECALL GRAPH"""

val = {'LR':rec[0],'SVM':rec[1],'KNN':rec[2],'RF':rec[3],'NB':rec[4],'DT':rec[5]}
model_name = list(val.keys())
values = list(val.values())


axes = plt.axes()
axes.set_ylim([0.60, 1.0])
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('Recall Graph')
color = ['r','g','b','c','m','y','g','r']
plt.bar(model_name,values,color=color,width = 0.4)
plt.show()

mod = pd.DataFrame({
     'Model': ['Logistic Regression','SVM','KNN', 'Random Forest', 'Naive Bayes','Decision Tree'],
    'Score': [
        rec[0],
        rec[1],
        rec[2],
        rec[3],
        rec[4],
        rec[5]

    ]})
mod.sort_values(by='Score', ascending=False)

"""# F1 SCORE GRPAH"""

val = {'LR':f1_s[0],'SVM':f1_s[1],'KNN':f1_s[2],'RF':f1_s[3],'NB':f1_s[4],'DT':f1_s[5]}
model_name = list(val.keys())
values = list(val.values())


axes = plt.axes()
axes.set_ylim([0.60, 1.0])
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('F1 SCORE  Graph')
color = ['r','g','b','c','m','y','g','r']
plt.bar(model_name,values,color=color,width = 0.4)
plt.show()

mod = pd.DataFrame({
    'Model': ['Logistic Regression','SVM','KNN', 'Random Forest', 'Naive Bayes','Decision Tree'],
    'Score': [
        f1_s[0],
        f1_s[1],
        f1_s[2],
        f1_s[3],
        f1_s[4],
        f1_s[5]

    ]})
mod.sort_values(by='Score', ascending=False)

"""# ROC CURVE"""

def rc_curv():
    for i,model in enumerate(models):
        cr_probs = model.predict_proba(x_test)
        cr_probs = cr_probs[:, 1]
        cr_auc = roc_auc_score(test_y, cr_probs)
        #cr_auc=np.append(cr_auc,cr_auc)
        cr_fpr,cr_tpr, _ = roc_curve(test_y,cr_probs)
        #cr_fpr=np.append(cr_fpr,cr_fpr)
        #cr_tpr=np.append(cr_tpr,cr_tpr)
        print(model)
        print('----------------------------------------------------------------------------------')
        plt.plot(cr_fpr,cr_tpr, marker='*',label='(AUROC = %0.10f)'% cr_auc)
        plt.plot([0, 1], [0, 1],'r--')
        plt.title('ROC PLOT')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.legend()
        #plt.savefig('roc_grpah.jpg')
        plt.show()
        print('--------------------------------------------------------------------------------')

rc_curv()

"""# COMMON ROC GRPAH"""

lr_probs = models[0].predict_proba(x_test)
sv_probs = models[1].predict_proba(x_test)
kn_probs = models[2].predict_proba(x_test)
rf_probs = models[3].predict_proba(x_test)
nb_probs = models[4].predict_proba(x_test)
dt_probs = models[5].predict_proba(x_test)

#Probabilities for the positive outcome is kept.
lr_probs = lr_probs[:, 1]
sv_probs = sv_probs[:, 1]
rf_probs = rf_probs[:, 1]
kn_probs = kn_probs[:, 1]
nb_probs = nb_probs[:, 1]
dt_probs = dt_probs[:, 1]

lr_auc = roc_auc_score(test_y, lr_probs)
rf_auc = roc_auc_score(test_y, rf_probs)
nb_auc = roc_auc_score(test_y, nb_probs)
sv_auc = roc_auc_score(test_y, sv_probs)
kn_auc = roc_auc_score(test_y, kn_probs)
dt_auc = roc_auc_score(test_y, dt_probs)

#printing AUROC  scores
print('Logistic : AUROC = %.10f' % (lr_auc))
print('SVM : AUROC = %.10f' % (sv_auc))
print('Random Forest: AUROC = %.10f' % (rf_auc))
print('KNN : AUROC = %.10f' % (kn_auc))
print('Naive Bayes: AUROC = %.10f' % (nb_auc))
print('Decision Tree: AUROC = %.10f' % (dt_auc))

#Calculate ROC curve
lr_fpr,lr_tpr, _ = roc_curve(test_y,lr_probs)
sv_fpr,sv_tpr, _ =  roc_curve(test_y, sv_probs)
rf_fpr, rf_tpr, _ = roc_curve(test_y, rf_probs)
kn_fpr,kn_tpr, _ = roc_curve(test_y, kn_probs)
nb_fpr, nb_tpr, _ = roc_curve(test_y, nb_probs)
dt_fpr, dt_tpr, _ = roc_curve(test_y, dt_probs)

#plotting the diagram
plt.plot(lr_fpr,lr_tpr, marker='*', label='Logistic (AUROC = %0.10f)' % lr_auc)
plt.plot(sv_fpr,sv_tpr, marker='.', label='SVM (AUROC = %0.10f)' % sv_auc)
plt.plot(rf_fpr, rf_tpr, marker='+', label='Random Forest (AUROC = %0.10f)' % rf_auc)
plt.plot(kn_fpr,kn_tpr, marker='x', label='KNN (AUROC = %0.10f)' % kn_auc)
plt.plot(nb_fpr, nb_tpr, marker='d', label='Naive Bayes (AUROC = %0.10f)' % nb_auc)
plt.plot(dt_fpr, dt_tpr, marker='p', label='Decision Tree (AUROC = %0.10f)' % dt_auc)

plt.plot([0, 1], [0, 1],'r--')
plt.title('TESTING ROC PLOT')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
#plt.savefig('roc_grpah.jpg')
plt.show()

"""Tval is for taining data and other is for test data."""

tval = {'LR':tacc[0],'SVM':tacc[1],'KNN':tacc[2],'RF':tacc[3],'NB':tacc[4],'DT':tacc[5]}
val = {'LR':acc[0],'SVM':acc[1],'KNN':acc[2],'RF':acc[3],'NB':acc[4],'DT':acc[5]}
model_name = list(val.keys())
train_values = list(tval.values())
test_values = list(val.values())



axes = plt.axes()
axes.set_ylim([0.60, 1.0])

x_axis = np.arange(len(model_name))

plt.xticks(x_axis, model_name)
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('Accuracy Graph')

plt.bar(x_axis -0.2,train_values,0.4,label = 'Training')
plt.bar(x_axis + 0.2,test_values,0.4,label = 'Testing')
plt.legend(loc ='lower right')
plt.savefig("acc.png",dpi = 300)
plt.show()

tval = {'LR':tprec[0],'SVM':tprec[1],'KNN':tprec[2],'RF':tprec[3],'NB':tprec[4],'DT':tprec[5]}
val = {'LR':pre[0],'SVM':pre[1],'KNN':pre[2],'RF':pre[3],'NB':pre[4],'DT':pre[5]}
model_name = list(val.keys())
train_values = list(tval.values())
test_values = list(val.values())



axes = plt.axes()
axes.set_ylim([0.60, 1.0])

x_axis = np.arange(len(model_name))

plt.xticks(x_axis, model_name)
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('Precision Graph')

plt.bar(x_axis -0.2,train_values,0.4,label = 'Training')
plt.bar(x_axis + 0.2,test_values,0.4,label = 'Testing')
plt.legend(loc ='lower right')
plt.savefig("pre.png",dpi = 300)
plt.show()

tval = {'LR':trec[0],'SVM':trec[1],'KNN':trec[2],'RF':trec[3],'NB':trec[4],'DT':trec[5]}
val = {'LR':rec[0],'SVM':rec[1],'KNN':rec[2],'RF':rec[3],'NB':rec[4],'DT':rec[5]}
model_name = list(val.keys())
train_values = list(tval.values())
test_values = list(val.values())



axes = plt.axes()
axes.set_ylim([0.60, 1.0])

x_axis = np.arange(len(model_name))

plt.xticks(x_axis, model_name)
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('Recall Graph')

plt.bar(x_axis -0.2,train_values,0.4,label = 'Training')
plt.bar(x_axis + 0.2,test_values,0.4,label = 'Testing')
plt.legend(loc ='lower right')
plt.savefig("rec.png",dpi = 300)
plt.show()

tval = {'LR':tf1[0],'SVM':tf1[1],'KNN':tf1[2],'RF':tf1[3],'NB':tf1[4],'DT':tf1[5]}
val = {'LR':f1_s[0],'SVM':f1_s[1],'KNN':f1_s[2],'RF':f1_s[3],'NB':f1_s[4],'DT':f1_s[5]}
model_name = list(val.keys())
train_values = list(tval.values())
test_values = list(val.values())



axes = plt.axes()
axes.set_ylim([0.60, 1.0])

x_axis = np.arange(len(model_name))

plt.xticks(x_axis, model_name)
plt.xlabel('Model Name')
plt.ylabel('Values')
plt.title('F1 score Graph')

plt.bar(x_axis -0.2,train_values,0.4,label = 'Training')
plt.bar(x_axis + 0.2,test_values,0.4,label = 'Testing')
plt.legend(loc ='lower right')
plt.savefig("f_1.png",dpi = 300)
plt.show()

fmodel = DecisionTreeClassifier(max_depth=5, random_state=42)
fmodel.fit(X_train, y_train)

print(y_test)
print(fmodel.predict(X_test))

final_model = RandomForestClassifier(random_state=42, n_jobs=-1, max_depth=5,n_estimators=50)
final_model.fit(X_train, y_train)

X_test.head()

y_test.head()

age = float(input("Enter age: "))
gender = float(input("Enter gender (0 for female, 1 for male): "))
glucose = float(input("Enter glucose level: "))
kcm = float(input("Enter kcm: "))
tropohin = float(input("Enter tropohin level: "))


input_data = np.array([age, gender, glucose, kcm, tropohin])
#input_data=np.array([-1.97354908, -1.41421356, -0.68275774, -0.26445666, -0.31617185])
input_data_reshaped = input_data.reshape(1, -1)
#norm_data=scaler.fit_transform(input_data_reshaped)

#print(norm_data)
prediction = fmodel.predict(input_data_reshaped)
print(prediction)

if prediction[0] == 0:
    print('The Person does not have Heart Disease')
else:
    print('The Person has Heart Disease')

# Default values - 64, 1, 160, 1.8, 0.012 === 0
# 76	1	144.0	297.50	0.024 ====1

